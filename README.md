# Fleece

<p align="center"><img src="./logo.jpg" width="250"  alt="Fleece Logo"></p>

Fleece is a Visual Studio Code extension that allows developers to generate code using natural language. It's powered by [dalai](https://github.com/cocktailpeanut/dalai), an open source project that uses [llama.cpp](https://github.com/ggerganov/llama.cpp) and [alpaca.cpp](https://github.com/antimatter15/alpaca.cpp) language models to understand and interpret natural language.

## Demo

![Fleece Demo](./demo.gif)

_The above demo showcases the comment-to-code feature of Fleece in real-time on an M1 Mac._

## Installation

1. Install Dalai globally:

```
npm install dalai -g
```

2. Follow the steps [here](https://github.com/cocktailpeanut/dalai#just-run-this) to install the models via dalai's readme.

3. Install the Fleece extension from the [VSCode extension marketplace](https://marketplace.visualstudio.com/items?itemName=kelden.fleece) or by building it from this repo or downloading the latest `.vsix` [release](https://github.com/keldenl/fleece/releases) in this repo.

4. Add variables
- Ctrl + Shift + P --> Preferences: Open User Settings (JSON)
    - Add "fleece.url": "ws://localhost:3000"
        - Modify  localhost:3000 to point to the llama server
    - Add "fleece.model": "llama.7B"
        - Modify  llama.7B to the model you want.
]
## Usage

Fleece currently has one feature: comment-to-code. An indicator for the hotkeys to trigger comment-to-code will show up automatically on comments. Simply press `command+option+c` on Mac to trigger the process. This will automatically start a Dalai server and send the comment as a request.

_Note that Fleece is limited by the model used and the training data, so it's only as good as the Llama or Alpaca model. More features like autocomplete or language chatbot to answer questions will be added in the future._

## Local Building and Installation

1. Clone the repository:
```
git clone git@github.com:keldenl/fleece.git
```
2. Install `vsce` globally (if not already installed):
```
npm install -g @vscode/vsce
```
3. In the cloned repository, run the following command to generate a `.vsix` file:
```
vsce package
```
4. This should generate a `.vsix` file, which can be installed in VS Code via the command palette (`Ctrl+Shift+P`) using the "Extensions: Install from VSIX..." command.

5. Alternatively, you can also build and run Fleece locally in VS Code using the following steps:
- Open the cloned repository in VS Code
- Press `F5` to start a local build and launch an instance of VS Code with the Fleece extension
- Use the extension in the launched instance of VS Code







## Contributing

Contributions to Fleece are welcome! To contribute, follow these guidelines:

1. Clone the repo.
2. Create a new branch.
3. Make your changes and commit them.
4. Open a pull request (PR) and describe your changes.
5. Collaborators will review the changes and approve/merge if they are satisfactory.

## Coding Guidelines

When contributing to Fleece, please follow these coding guidelines:

- Write clean and readable code with proper indentation and comments.
- Use meaningful and descriptive variable and function names.
- Keep functions short and focused on one task.
- Test your code thoroughly before committing changes.

## Disclaimer
Note that the model weights are only to be used for research purposes, as they are derivative of LLaMA, and uses the published instruction data from the Stanford Alpaca project which is generated by OpenAI, which itself disallows the usage of its outputs to train competing models.